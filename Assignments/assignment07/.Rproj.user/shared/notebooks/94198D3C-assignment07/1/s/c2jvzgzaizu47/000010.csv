"0",""
"0","#define three model specifications"
"0","#1. one parametric regression model - LASSO"
"0",""
"0"," #create a tuning grid"
"0","lasso_grid <- grid_regular(penalty(), levels = 10)"
"0","# create a linear_regression model so that you can tune the penalty parameter"
"0","# set the mixture parameter to 1 and use ""glmnet"" for the engine"
"0","lasso_mod <- linear_reg("
"0","  penalty = tune(), "
"0","  mixture = 1"
"0",") %>%"
"0","  set_engine(""glmnet"")"
"0",""
"0"," #create a workflow using your updated linear regression model you just created and the recipe defined above"
"0","lasso_wf <- workflow() %>%"
"0","  add_recipe(chicago_rec) %>%"
"0","  add_model(lasso_mod) "
"0",""
"0"," # perform hyperparameter tuning using the lasso_grid and the cross_validation folds created above by modifying the line below"
"0",""
"0","lasso_cv <- lasso_wf %>%"
"0","  tune_grid("
"0","    resamples = chi_fold,"
"0","    grid = lasso_grid"
"0","  ) #是一个包含tibble的表格，每个fold含有rmse和rsq两种metric"
"0",""
"0"," #select the best model based on the ""rmse"" metric"
"0","lasso_best <- lasso_cv %>%"
"0","  select_best(metric = ""rmse"")"
"0",""
"0"," #use the finalize_workflow() function with your lasso workflow and the best model to update (or ""finalize"") the workflow by modifying the line below"
"0","lasso_final <- finalize_workflow("
"0","  lasso_wf,"
"0","  parameters = lasso_best"
"0",")"
"0",""
"0","#Calculate the MAE and RMSE for each resample."
"0","ctrl <- control_resamples(save_pred = TRUE)"
"0","lasso_fit_rs <- lasso_final %>%"
"0","  fit_resamples(chi_fold, control = ctrl) "
"0",""
"0","collect_predictions(lasso_fit_rs)"
