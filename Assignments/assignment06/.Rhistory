as_tibble() %>%
pull()
gini_left <- 1 - sum((left_prep)^2)
#2. right
right_prep<- prop.table(table(right)) %>% #an intermediate variable help calculate gini_right
as_tibble() %>%
pull()
gini_right <- 1 - sum((right_prep)^2)
#calculate the overall gini index
#1. define S
S <- length(left) + length(right)
#2. calculate the gini_combined
gini_combined <- ((length(left)/S)*gini_left) + ((length(right)/S)*gini_right)
# return
return(
list(
gini_left = gini_left,
gini_right = gini_right,
gini_combined = gini_combined
)
)
}
#test the function
calc_gini_k(left = c(0, 0, 0), right = c(1, 1, 1))
calc_gini_k(left = c(0, 0, 1, 1), right = c(0, 0, 1, 1))
calc_gini_k(left = dt_analysis$rat_burrow[1:5], right = dt_analysis$rat_burrow[6:10])
#generate the data set
set.seed(20220318)
data <- tibble(
x1 = runif(100, min = 0, max = 1),
x2 = runif(100, min = 0, max = 1),
x1_prob = runif(100, min = 0, max = 1),
x2_prob = runif(100, min = 0, max = 1)
) %>%
mutate(
y = case_when(
x1_prob > x1 & x2_prob > x2 ~ "a",
x1_prob < x1 & x2_prob > x2 ~ "b",
x1_prob > x1 & x2_prob < x2 ~ "c",
x1_prob < x1 & x2_prob < x2 ~ "d",
)
) %>%
mutate(y = factor(y)) %>%
select(x1, y)
#Evaluate all of the non-empty splits to decide the node
#1. the vector of all gini_combined for each node
gini_combined <- map_dbl(
.x = 1:99,
.f = ~calc_gini_k(
left = data$y[1:.x],
right = data$y[(.x + 1):100]
)$gini_combined
) %>%
glimpse()
#this it the vector of all gini_combined for each node.
#2. to find the minimum gini_combined and the corresponding order of it
gini_combined %>%
as_tibble() %>%
mutate(order = 1:99) %>%
arrange(value) %>%
glimpse()
#find the corresponding predictor for our best split node
data$x1[11]
#So, the optimal choice of the split node is to split the data set after x1 = 0.5276528, the 11th observation we have.
set.seed(20200302)
# input the data
rats <- tribble(~rat_burrow, ~pizza_proximity,
1, 0.01,
1, 0.05,
1, 0.08,
0, 0.1,
0, 0.12,
1, 0.2,
1, 0.3,
1, 0.5,
1, 0.75,
0, 0.9,
1, 1,
0, 1.2,
0, 2.2,
0, 2.3,
0, 2.5,
1, 3,
0, 3.5,
0, 4,
0, 5,
0, 7
) %>%
mutate(rat_burrow = factor(rat_burrow)) %>%
transmute(
rat_burrow = as.numeric(as.character(rat_burrow)),
pizza_proximity = pizza_proximity) #transform the factor to numeric form
# split into training and testing data
split <- initial_split(rats, prop = 0.75)
rats_training <- training(split)
rats_testing <- testing(split)
rats_k1 <- vfold_cv(data = rats_training,
v = 3)
rats_k3 <- vfold_cv(data = rats_training,
v = 3)
rats_kn <- vfold_cv(data = rats_training,
v = 3)
#Extract the analysis data and assessment data from the first resample in rats_k1, rats_k3, and rats_kn.
analysis_k1 <- rats_k1$splits[[1]] %>% analysis()
assess_k1 <- rats_k1$splits[[1]] %>% assessment()
analysis_k3 <- rats_k3$splits[[1]] %>% analysis()
assess_k3 <- rats_k3$splits[[1]] %>% assessment()
analysis_kn <- rats_kn$splits[[1]] %>% analysis()
assess_kn <- rats_kn$splits[[1]] %>% assessment()
#calculate y_hat for each assessment data
#for k = 1
# (1) create a knn model specification
knn_mod_k1 <-
nearest_neighbor(neighbors = 1) %>%
set_engine(engine = "kknn") %>%
set_mode(mode = "regression")
# (2) fit the knn model specification on the training data
knn_fit_k1 <- knn_mod_k1 %>%
fit(formula = rat_burrow ~ pizza_proximity, data = analysis_k1)
# (3) use the estimated model to predict values in the testing data
prediction_k1 <-
bind_cols(assess_k1,
predict(object = knn_fit_k1, new_data = assess_k1)
)
#for k = 3
# (1) create a knn model specification
knn_mod_k3 <-
nearest_neighbor(neighbors = 3) %>%
set_engine(engine = "kknn") %>%
set_mode(mode = "regression")
# (2) fit the knn model specification on the training data
knn_fit_k3 <- knn_mod_k3 %>%
fit(formula =  rat_burrow ~ pizza_proximity, data = analysis_k3)
# (3) use the estimated model to predict values in the testing data
prediction_k3 <-
bind_cols(assess_k3,
predict(object = knn_fit_k3, new_data = assess_k3)
)
#for k = n, let n = 5 because we have 5 observations in total in our assessment data set
# (1) create a knn model specification
knn_mod_kn <-
nearest_neighbor(neighbors = 5) %>%
set_engine(engine = "kknn") %>%
set_mode(mode = "regression")
# (2) fit the knn model specification on the training data
knn_fit_kn <- knn_mod_kn %>%
fit(formula = rat_burrow ~ pizza_proximity, data = analysis_kn)
# (3) use the estimated model to predict values in the testing data
prediction_kn <-
bind_cols(assess_kn,
predict(object = knn_fit_kn, new_data = assess_kn)
)
# Include the data frame in your R Markdown document
knitr::kable(prediction_k1)
knitr::kable(prediction_k3)
knitr::kable(prediction_kn)
set.seed(20200302)
# input the data
rats <- tribble(~rat_burrow, ~pizza_proximity,
1, 0.01,
1, 0.05,
1, 0.08,
0, 0.1,
0, 0.12,
1, 0.2,
1, 0.3,
1, 0.5,
1, 0.75,
0, 0.9,
1, 1,
0, 1.2,
0, 2.2,
0, 2.3,
0, 2.5,
1, 3,
0, 3.5,
0, 4,
0, 5,
0, 7
) %>%
mutate(rat_burrow = factor(rat_burrow)) %>%
transmute(
rat_burrow = as.numeric(as.character(rat_burrow)),
pizza_proximity = pizza_proximity) #transform the factor to numeric form
# split into training and testing data
split <- initial_split(rats, prop = 0.75)
rats_training <- training(split)
rats_testing <- testing(split)
rats_k1 <- vfold_cv(data = rats_training,
v = 3)
rats_k3 <- vfold_cv(data = rats_training,
v = 3)
rats_kn <- vfold_cv(data = rats_training,
v = 3)
#Extract the analysis data and assessment data from the first resample in rats_k1, rats_k3, and rats_kn.
analysis_k1 <- rats_k1$splits[[1]] %>% analysis()
assess_k1 <- rats_k1$splits[[1]] %>% assessment()
analysis_k3 <- rats_k3$splits[[1]] %>% analysis()
assess_k3 <- rats_k3$splits[[1]] %>% assessment()
analysis_kn <- rats_kn$splits[[1]] %>% analysis()
assess_kn <- rats_kn$splits[[1]] %>% assessment()
#calculate y_hat for each assessment data
#for k = 1
# (1) create a knn model specification
knn_mod_k1 <-
nearest_neighbor(neighbors = 1) %>%
set_engine(engine = "kknn") %>%
set_mode(mode = "regression")
# (2) fit the knn model specification on the training data
knn_fit_k1 <- knn_mod_k1 %>%
fit(formula = rat_burrow ~ pizza_proximity, data = analysis_k1)
# (3) use the estimated model to predict values in the testing data
prediction_k1 <-
bind_cols(assess_k1,
predict(object = knn_fit_k1, new_data = assess_k1)
)
#for k = 3
# (1) create a knn model specification
knn_mod_k3 <-
nearest_neighbor(neighbors = 3) %>%
set_engine(engine = "kknn") %>%
set_mode(mode = "regression")
# (2) fit the knn model specification on the training data
knn_fit_k3 <- knn_mod_k3 %>%
fit(formula =  rat_burrow ~ pizza_proximity, data = analysis_k3)
# (3) use the estimated model to predict values in the testing data
prediction_k3 <-
bind_cols(assess_k3,
predict(object = knn_fit_k3, new_data = assess_k3)
)
#for k = n, let n = 5 because we have 5 observations in total in our assessment data set
# (1) create a knn model specification
knn_mod_kn <-
nearest_neighbor(neighbors = 5) %>%
set_engine(engine = "kknn") %>%
set_mode(mode = "classification")
# (2) fit the knn model specification on the training data
knn_fit_kn <- knn_mod_kn %>%
fit(formula = rat_burrow ~ pizza_proximity, data = analysis_kn)
set.seed(20200302)
# input the data
rats <- tribble(~rat_burrow, ~pizza_proximity,
1, 0.01,
1, 0.05,
1, 0.08,
0, 0.1,
0, 0.12,
1, 0.2,
1, 0.3,
1, 0.5,
1, 0.75,
0, 0.9,
1, 1,
0, 1.2,
0, 2.2,
0, 2.3,
0, 2.5,
1, 3,
0, 3.5,
0, 4,
0, 5,
0, 7
) %>%
mutate(rat_burrow = factor(rat_burrow))
# split into training and testing data
split <- initial_split(rats, prop = 0.75)
rats_training <- training(split)
rats_testing <- testing(split)
rats_k1 <- vfold_cv(data = rats_training,
v = 3)
rats_k3 <- vfold_cv(data = rats_training,
v = 3)
rats_kn <- vfold_cv(data = rats_training,
v = 3)
#Extract the analysis data and assessment data from the first resample in rats_k1, rats_k3, and rats_kn.
analysis_k1 <- rats_k1$splits[[1]] %>% analysis()
assess_k1 <- rats_k1$splits[[1]] %>% assessment()
analysis_k3 <- rats_k3$splits[[1]] %>% analysis()
assess_k3 <- rats_k3$splits[[1]] %>% assessment()
analysis_kn <- rats_kn$splits[[1]] %>% analysis()
assess_kn <- rats_kn$splits[[1]] %>% assessment()
#calculate y_hat for each assessment data
#for k = 1
# (1) create a knn model specification
knn_mod_k1 <-
nearest_neighbor(neighbors = 1) %>%
set_engine(engine = "kknn") %>%
set_mode(mode = "classification")
# (2) fit the knn model specification on the training data
knn_fit_k1 <- knn_mod_k1 %>%
fit(formula = rat_burrow ~ pizza_proximity, data = analysis_k1)
# (3) use the estimated model to predict values in the testing data
prediction_k1 <-
bind_cols(assess_k1,
predict(object = knn_fit_k1, new_data = assess_k1)
)
#for k = 3
# (1) create a knn model specification
knn_mod_k3 <-
nearest_neighbor(neighbors = 3) %>%
set_engine(engine = "kknn") %>%
set_mode(mode = "classification")
# (2) fit the knn model specification on the training data
knn_fit_k3 <- knn_mod_k3 %>%
fit(formula =  rat_burrow ~ pizza_proximity, data = analysis_k3)
# (3) use the estimated model to predict values in the testing data
prediction_k3 <-
bind_cols(assess_k3,
predict(object = knn_fit_k3, new_data = assess_k3)
)
#for k = n, let n = 5 because we have 5 observations in total in our assessment data set
# (1) create a knn model specification
knn_mod_kn <-
nearest_neighbor(neighbors = 5) %>%
set_engine(engine = "kknn") %>%
set_mode(mode = "classification")
# (2) fit the knn model specification on the training data
knn_fit_kn <- knn_mod_kn %>%
fit(formula = rat_burrow ~ pizza_proximity, data = analysis_kn)
# (3) use the estimated model to predict values in the testing data
prediction_kn <-
bind_cols(assess_kn,
predict(object = knn_fit_kn, new_data = assess_kn)
)
# Include the data frame in your R Markdown document
knitr::kable(prediction_k1)
knitr::kable(prediction_k3)
knitr::kable(prediction_kn)
#using the data, calculate the following “by hand” and show your work
knitr::include_graphics("data/exercise03.png")
set.seed(20200302)
# input the data
rats <- tribble(~rat_burrow, ~pizza_proximity,
1, 0.01,
1, 0.05,
1, 0.08,
0, 0.1,
0, 0.12,
1, 0.2,
1, 0.3,
1, 0.5,
1, 0.75,
0, 0.9,
1, 1,
0, 1.2,
0, 2.2,
0, 2.3,
0, 2.5,
1, 3,
0, 3.5,
0, 4,
0, 5,
0, 7
) %>%
mutate(rat_burrow = factor(rat_burrow))
# split into training and testing data
split <- initial_split(rats, prop = 0.75)
rats_training <- training(split)
rats_testing <- testing(split)
rats_k1 <- vfold_cv(data = rats_training,
v = 3)
rats_k3 <- vfold_cv(data = rats_training,
v = 3)
rats_kn <- vfold_cv(data = rats_training,
v = 3)
#Extract the analysis data and assessment data from the first resample in rats_k1, rats_k3, and rats_kn.
analysis_k1 <- rats_k1$splits[[1]] %>% analysis()
assess_k1 <- rats_k1$splits[[1]] %>% assessment()
analysis_k3 <- rats_k3$splits[[1]] %>% analysis()
assess_k3 <- rats_k3$splits[[1]] %>% assessment()
analysis_kn <- rats_kn$splits[[1]] %>% analysis()
assess_kn <- rats_kn$splits[[1]] %>% assessment()
#calculate y_hat for each assessment data
#for k = 1
# (1) create a knn model specification
knn_mod_k1 <-
nearest_neighbor(neighbors = 1) %>%
set_engine(engine = "kknn") %>%
set_mode(mode = "classification")
# (2) fit the knn model specification on the training data
knn_fit_k1 <- knn_mod_k1 %>%
fit(formula = rat_burrow ~ pizza_proximity, data = analysis_k1)
# (3) use the estimated model to predict values in the testing data
prediction_k1 <-
bind_cols(assess_k1,
predict(object = knn_fit_k1, new_data = assess_k1)
)
#for k = 3
# (1) create a knn model specification
knn_mod_k3 <-
nearest_neighbor(neighbors = 3) %>%
set_engine(engine = "kknn") %>%
set_mode(mode = "classification")
# (2) fit the knn model specification on the training data
knn_fit_k3 <- knn_mod_k3 %>%
fit(formula =  rat_burrow ~ pizza_proximity, data = analysis_k3)
# (3) use the estimated model to predict values in the testing data
prediction_k3 <-
bind_cols(assess_k3,
predict(object = knn_fit_k3, new_data = assess_k3)
)
#for k = n, let n = 5 because we have 5 observations in total in our assessment data set
# (1) create a knn model specification
knn_mod_kn <-
nearest_neighbor(neighbors = 5) %>%
set_engine(engine = "kknn") %>%
set_mode(mode = "classification")
# (2) fit the knn model specification on the training data
knn_fit_kn <- knn_mod_kn %>%
fit(formula = rat_burrow ~ pizza_proximity, data = analysis_kn)
# (3) use the estimated model to predict values in the testing data
prediction_kn <-
bind_cols(assess_kn,
predict(object = knn_fit_kn, new_data = assess_kn)
)
# Include the data frame in your R Markdown document
knitr::kable(prediction_k1)
knitr::kable(prediction_k3)
knitr::kable(prediction_kn)
#calculate the accuracy and confusion matrix by hand
knitr::include_graphics("data/accuracy4_2.png")
set.seed(20200302)
# input the data
rats <- tribble(~rat_burrow, ~pizza_proximity,
1, 0.01,
1, 0.05,
1, 0.08,
0, 0.1,
0, 0.12,
1, 0.2,
1, 0.3,
1, 0.5,
1, 0.75,
0, 0.9,
1, 1,
0, 1.2,
0, 2.2,
0, 2.3,
0, 2.5,
1, 3,
0, 3.5,
0, 4,
0, 5,
0, 7
) %>%
mutate(rat_burrow = factor(rat_burrow))
# split into training and testing data
split <- initial_split(rats, prop = 0.75)
rats_training <- training(split)
rats_testing <- testing(split)
rats_k1 <- vfold_cv(data = rats_training,
v = 3)
rats_k3 <- vfold_cv(data = rats_training,
v = 3)
rats_kn <- vfold_cv(data = rats_training,
v = 3)
#Extract the analysis data and assessment data from the first resample in rats_k1, rats_k3, and rats_kn.
analysis_k1 <- rats_k1$splits[[1]] %>% analysis()
assess_k1 <- rats_k1$splits[[1]] %>% assessment()
analysis_k3 <- rats_k3$splits[[1]] %>% analysis()
assess_k3 <- rats_k3$splits[[1]] %>% assessment()
analysis_kn <- rats_kn$splits[[1]] %>% analysis()
assess_kn <- rats_kn$splits[[1]] %>% assessment()
#calculate y_hat for each assessment data
#for k = 1
# (1) create a knn model specification
knn_mod_k1 <-
nearest_neighbor(neighbors = 1) %>%
set_engine(engine = "kknn") %>%
set_mode(mode = "classification")
# (2) fit the knn model specification on the training data
knn_fit_k1 <- knn_mod_k1 %>%
fit(formula = rat_burrow ~ pizza_proximity, data = analysis_k1)
# (3) use the estimated model to predict values in the testing data
prediction_k1 <-
bind_cols(assess_k1,
predict(object = knn_fit_k1, new_data = assess_k1)
)
#for k = 3
# (1) create a knn model specification
knn_mod_k3 <-
nearest_neighbor(neighbors = 3) %>%
set_engine(engine = "kknn") %>%
set_mode(mode = "classification")
# (2) fit the knn model specification on the training data
knn_fit_k3 <- knn_mod_k3 %>%
fit(formula =  rat_burrow ~ pizza_proximity, data = analysis_k3)
# (3) use the estimated model to predict values in the testing data
prediction_k3 <-
bind_cols(assess_k3,
predict(object = knn_fit_k3, new_data = assess_k3)
)
#for k = n, let n = 5 because we have 5 observations in total in our assessment data set
# (1) create a knn model specification
knn_mod_kn <-
nearest_neighbor(neighbors = 5) %>%
set_engine(engine = "kknn") %>%
set_mode(mode = "classification")
# (2) fit the knn model specification on the training data
knn_fit_kn <- knn_mod_kn %>%
fit(formula = rat_burrow ~ pizza_proximity, data = analysis_kn)
# (3) use the estimated model to predict values in the testing data
prediction_kn <-
bind_cols(assess_kn,
predict(object = knn_fit_kn, new_data = assess_kn)
)
# Include the data frame in your R Markdown document
knitr::kable(prediction_k1)
knitr::kable(prediction_k3)
knitr::kable(prediction_kn)
#calculate the accuracy and confusion matrix by hand
knitr::include_graphics("data/stretch01.png")
